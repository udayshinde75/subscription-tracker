"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// platforms/solidjs.ts
var solidjs_exports = {};
__export(solidjs_exports, {
  serve: () => serve
});
module.exports = __toCommonJS(solidjs_exports);

// src/client/utils.ts
var import_qstash = require("@upstash/qstash");
var makeNotifyRequest = async (requester, eventId, eventData) => {
  const result = await requester.request({
    path: ["v2", "notify", eventId],
    method: "POST",
    body: typeof eventData === "string" ? eventData : JSON.stringify(eventData)
  });
  return result;
};
var makeCancelRequest = async (requester, workflowRunId) => {
  await requester.request({
    path: ["v2", "workflows", "runs", `${workflowRunId}?cancel=true`],
    method: "DELETE",
    parseResponseAsJson: false
  });
  return true;
};
var getSteps = async (requester, workflowRunId, messageId, debug) => {
  try {
    const steps = await requester.request({
      path: ["v2", "workflows", "runs", workflowRunId],
      parseResponseAsJson: true
    });
    if (!messageId) {
      await debug?.log("INFO", "ENDPOINT_START", {
        message: `Pulled ${steps.length} steps from QStashand returned them without filtering with messageId.`
      });
      return { steps, workflowRunEnded: false };
    } else {
      const index = steps.findIndex((item) => item.messageId === messageId);
      if (index === -1) {
        return { steps: [], workflowRunEnded: false };
      }
      const filteredSteps = steps.slice(0, index + 1);
      await debug?.log("INFO", "ENDPOINT_START", {
        message: `Pulled ${steps.length} steps from QStash and filtered them to ${filteredSteps.length} using messageId.`
      });
      return { steps: filteredSteps, workflowRunEnded: false };
    }
  } catch (error) {
    if (error instanceof import_qstash.QstashError && error.status === 404) {
      await debug?.log("WARN", "ENDPOINT_START", {
        message: "Couldn't fetch workflow run steps. This can happen if the workflow run succesfully ends before some callback is executed.",
        error
      });
      return { steps: void 0, workflowRunEnded: true };
    } else {
      throw error;
    }
  }
};

// src/constants.ts
var WORKFLOW_ID_HEADER = "Upstash-Workflow-RunId";
var WORKFLOW_INIT_HEADER = "Upstash-Workflow-Init";
var WORKFLOW_URL_HEADER = "Upstash-Workflow-Url";
var WORKFLOW_FAILURE_HEADER = "Upstash-Workflow-Is-Failure";
var WORKFLOW_FEATURE_HEADER = "Upstash-Feature-Set";
var WORKFLOW_INVOKE_COUNT_HEADER = "Upstash-Workflow-Invoke-Count";
var WORKFLOW_PROTOCOL_VERSION = "1";
var WORKFLOW_PROTOCOL_VERSION_HEADER = "Upstash-Workflow-Sdk-Version";
var DEFAULT_CONTENT_TYPE = "application/json";
var NO_CONCURRENCY = 1;
var DEFAULT_RETRIES = 3;
var VERSION = "v0.2.7";
var SDK_TELEMETRY = `@upstash/workflow@${VERSION}`;
var TELEMETRY_HEADER_SDK = "Upstash-Telemetry-Sdk";
var TELEMETRY_HEADER_FRAMEWORK = "Upstash-Telemetry-Framework";
var TELEMETRY_HEADER_RUNTIME = "Upstash-Telemetry-Runtime";

// src/error.ts
var import_qstash2 = require("@upstash/qstash");
var WorkflowError = class extends import_qstash2.QstashError {
  constructor(message) {
    super(message);
    this.name = "WorkflowError";
  }
};
var WorkflowAbort = class extends Error {
  stepInfo;
  stepName;
  /**
   * whether workflow is to be canceled on abort
   */
  cancelWorkflow;
  /**
   *
   * @param stepName name of the aborting step
   * @param stepInfo step information
   * @param cancelWorkflow
   */
  constructor(stepName, stepInfo, cancelWorkflow = false) {
    super(
      `This is an Upstash Workflow error thrown after a step executes. It is expected to be raised. Make sure that you await for each step. Also, if you are using try/catch blocks, you should not wrap context.run/sleep/sleepUntil/call methods with try/catch. Aborting workflow after executing step '${stepName}'.`
    );
    this.name = "WorkflowAbort";
    this.stepName = stepName;
    this.stepInfo = stepInfo;
    this.cancelWorkflow = cancelWorkflow;
  }
};
var formatWorkflowError = (error) => {
  return error instanceof Error ? {
    error: error.name,
    message: error.message
  } : {
    error: "Error",
    message: `An error occured while executing workflow: '${typeof error === "string" ? error : JSON.stringify(error)}'`
  };
};

// src/utils.ts
var NANOID_CHARS = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789-_";
var NANOID_LENGTH = 21;
function getRandomInt() {
  return Math.floor(Math.random() * NANOID_CHARS.length);
}
function nanoid() {
  return Array.from({ length: NANOID_LENGTH }).map(() => NANOID_CHARS[getRandomInt()]).join("");
}
function getWorkflowRunId(id) {
  return `wfr_${id ?? nanoid()}`;
}
function decodeBase64(base64) {
  const binString = atob(base64);
  try {
    const intArray = Uint8Array.from(binString, (m) => m.codePointAt(0));
    return new TextDecoder().decode(intArray);
  } catch (error) {
    console.warn(
      `Upstash Qstash: Failed while decoding base64 "${base64}". Decoding with atob and returning it instead. ${error}`
    );
    return binString;
  }
}

// src/context/steps.ts
var BaseLazyStep = class _BaseLazyStep {
  stepName;
  constructor(stepName) {
    if (!stepName) {
      throw new WorkflowError(
        "A workflow step name cannot be undefined or an empty string. Please provide a name for your workflow step."
      );
    }
    this.stepName = stepName;
  }
  /**
   * parse the out field of a step result.
   *
   * will be called when returning the steps to the context from auto executor
   *
   * @param out field of the step
   * @returns parsed out field
   */
  parseOut(out) {
    if (out === void 0) {
      if (this.allowUndefinedOut) {
        return void 0;
      } else {
        throw new WorkflowError(
          `Error while parsing output of ${this.stepType} step. Expected a string, but got: undefined`
        );
      }
    }
    if (typeof out === "object") {
      if (this.stepType !== "Wait") {
        console.warn(
          `Error while parsing ${this.stepType} step output. Expected a string, but got object. Please reach out to Upstash Support.`
        );
        return out;
      }
      return {
        ...out,
        eventData: _BaseLazyStep.tryParsing(out.eventData)
      };
    }
    if (typeof out !== "string") {
      throw new WorkflowError(
        `Error while parsing output of ${this.stepType} step. Expected a string or undefined, but got: ${typeof out}`
      );
    }
    return this.safeParseOut(out);
  }
  safeParseOut(out) {
    return _BaseLazyStep.tryParsing(out);
  }
  static tryParsing(stepOut) {
    try {
      return JSON.parse(stepOut);
    } catch {
      return stepOut;
    }
  }
};
var LazyFunctionStep = class extends BaseLazyStep {
  stepFunction;
  stepType = "Run";
  allowUndefinedOut = true;
  constructor(stepName, stepFunction) {
    super(stepName);
    this.stepFunction = stepFunction;
  }
  getPlanStep(concurrent, targetStep) {
    return {
      stepId: 0,
      stepName: this.stepName,
      stepType: this.stepType,
      concurrent,
      targetStep
    };
  }
  async getResultStep(concurrent, stepId) {
    let result = this.stepFunction();
    if (result instanceof Promise) {
      result = await result;
    }
    return {
      stepId,
      stepName: this.stepName,
      stepType: this.stepType,
      out: result,
      concurrent
    };
  }
};
var LazySleepStep = class extends BaseLazyStep {
  sleep;
  stepType = "SleepFor";
  allowUndefinedOut = true;
  constructor(stepName, sleep) {
    super(stepName);
    this.sleep = sleep;
  }
  getPlanStep(concurrent, targetStep) {
    return {
      stepId: 0,
      stepName: this.stepName,
      stepType: this.stepType,
      sleepFor: this.sleep,
      concurrent,
      targetStep
    };
  }
  async getResultStep(concurrent, stepId) {
    return await Promise.resolve({
      stepId,
      stepName: this.stepName,
      stepType: this.stepType,
      sleepFor: this.sleep,
      concurrent
    });
  }
};
var LazySleepUntilStep = class extends BaseLazyStep {
  sleepUntil;
  stepType = "SleepUntil";
  allowUndefinedOut = true;
  constructor(stepName, sleepUntil) {
    super(stepName);
    this.sleepUntil = sleepUntil;
  }
  getPlanStep(concurrent, targetStep) {
    return {
      stepId: 0,
      stepName: this.stepName,
      stepType: this.stepType,
      sleepUntil: this.sleepUntil,
      concurrent,
      targetStep
    };
  }
  async getResultStep(concurrent, stepId) {
    return await Promise.resolve({
      stepId,
      stepName: this.stepName,
      stepType: this.stepType,
      sleepUntil: this.sleepUntil,
      concurrent
    });
  }
  safeParseOut() {
    return void 0;
  }
};
var LazyCallStep = class _LazyCallStep extends BaseLazyStep {
  url;
  method;
  body;
  headers;
  retries;
  timeout;
  flowControl;
  stepType = "Call";
  allowUndefinedOut = false;
  constructor(stepName, url, method, body, headers, retries, timeout, flowControl) {
    super(stepName);
    this.url = url;
    this.method = method;
    this.body = body;
    this.headers = headers;
    this.retries = retries;
    this.timeout = timeout;
    this.flowControl = flowControl;
  }
  getPlanStep(concurrent, targetStep) {
    return {
      stepId: 0,
      stepName: this.stepName,
      stepType: this.stepType,
      concurrent,
      targetStep
    };
  }
  async getResultStep(concurrent, stepId) {
    return await Promise.resolve({
      stepId,
      stepName: this.stepName,
      stepType: this.stepType,
      concurrent,
      callUrl: this.url,
      callMethod: this.method,
      callBody: this.body,
      callHeaders: this.headers
    });
  }
  safeParseOut(out) {
    const { header, status, body } = JSON.parse(out);
    const responseHeaders = new Headers(header);
    if (_LazyCallStep.isText(responseHeaders.get("content-type"))) {
      const bytes = new Uint8Array(out.length);
      for (let i = 0; i < out.length; i++) {
        bytes[i] = out.charCodeAt(i);
      }
      const processedResult = new TextDecoder().decode(bytes);
      const newBody = JSON.parse(processedResult).body;
      return {
        status,
        header,
        body: BaseLazyStep.tryParsing(newBody)
      };
    } else {
      return { header, status, body };
    }
  }
  static applicationHeaders = /* @__PURE__ */ new Set([
    "application/json",
    "application/xml",
    "application/javascript",
    "application/x-www-form-urlencoded",
    "application/xhtml+xml",
    "application/ld+json",
    "application/rss+xml",
    "application/atom+xml"
  ]);
  static isText = (contentTypeHeader) => {
    if (!contentTypeHeader) {
      return false;
    }
    if (_LazyCallStep.applicationHeaders.has(contentTypeHeader)) {
      return true;
    }
    if (contentTypeHeader.startsWith("text/")) {
      return true;
    }
    return false;
  };
};
var LazyWaitForEventStep = class extends BaseLazyStep {
  eventId;
  timeout;
  stepType = "Wait";
  allowUndefinedOut = false;
  constructor(stepName, eventId, timeout) {
    super(stepName);
    this.eventId = eventId;
    this.timeout = timeout;
  }
  getPlanStep(concurrent, targetStep) {
    return {
      stepId: 0,
      stepName: this.stepName,
      stepType: this.stepType,
      waitEventId: this.eventId,
      timeout: this.timeout,
      concurrent,
      targetStep
    };
  }
  async getResultStep(concurrent, stepId) {
    return await Promise.resolve({
      stepId,
      stepName: this.stepName,
      stepType: this.stepType,
      waitEventId: this.eventId,
      timeout: this.timeout,
      concurrent
    });
  }
  safeParseOut(out) {
    const result = JSON.parse(out);
    return {
      ...result,
      eventData: BaseLazyStep.tryParsing(result.eventData)
    };
  }
};
var LazyNotifyStep = class extends LazyFunctionStep {
  stepType = "Notify";
  constructor(stepName, eventId, eventData, requester) {
    super(stepName, async () => {
      const notifyResponse = await makeNotifyRequest(requester, eventId, eventData);
      return {
        eventId,
        eventData,
        notifyResponse
      };
    });
  }
  safeParseOut(out) {
    const result = JSON.parse(out);
    return {
      ...result,
      eventData: BaseLazyStep.tryParsing(result.eventData)
    };
  }
};
var LazyInvokeStep = class extends BaseLazyStep {
  stepType = "Invoke";
  params;
  allowUndefinedOut = false;
  constructor(stepName, {
    workflow,
    body,
    headers = {},
    workflowRunId,
    retries,
    flowControl
  }) {
    super(stepName);
    this.params = {
      workflow,
      body,
      headers,
      workflowRunId: getWorkflowRunId(workflowRunId),
      retries,
      flowControl
    };
  }
  getPlanStep(concurrent, targetStep) {
    return {
      stepId: 0,
      stepName: this.stepName,
      stepType: this.stepType,
      concurrent,
      targetStep
    };
  }
  /**
   * won't be used as it's the server who will add the result step
   * in Invoke step.
   */
  getResultStep(concurrent, stepId) {
    return Promise.resolve({
      stepId,
      stepName: this.stepName,
      stepType: this.stepType,
      concurrent
    });
  }
  safeParseOut(out) {
    const result = JSON.parse(out);
    return {
      ...result,
      body: BaseLazyStep.tryParsing(result.body)
    };
  }
};

// node_modules/neverthrow/dist/index.es.js
var defaultErrorConfig = {
  withStackTrace: false
};
var createNeverThrowError = (message, result, config = defaultErrorConfig) => {
  const data = result.isOk() ? { type: "Ok", value: result.value } : { type: "Err", value: result.error };
  const maybeStack = config.withStackTrace ? new Error().stack : void 0;
  return {
    data,
    message,
    stack: maybeStack
  };
};
function __awaiter(thisArg, _arguments, P, generator) {
  function adopt(value) {
    return value instanceof P ? value : new P(function(resolve) {
      resolve(value);
    });
  }
  return new (P || (P = Promise))(function(resolve, reject) {
    function fulfilled(value) {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    }
    function rejected(value) {
      try {
        step(generator["throw"](value));
      } catch (e) {
        reject(e);
      }
    }
    function step(result) {
      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
    }
    step((generator = generator.apply(thisArg, [])).next());
  });
}
function __values(o) {
  var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
  if (m) return m.call(o);
  if (o && typeof o.length === "number") return {
    next: function() {
      if (o && i >= o.length) o = void 0;
      return { value: o && o[i++], done: !o };
    }
  };
  throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}
function __await(v) {
  return this instanceof __await ? (this.v = v, this) : new __await(v);
}
function __asyncGenerator(thisArg, _arguments, generator) {
  if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
  var g = generator.apply(thisArg, _arguments || []), i, q = [];
  return i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
    return this;
  }, i;
  function verb(n) {
    if (g[n]) i[n] = function(v) {
      return new Promise(function(a, b) {
        q.push([n, v, a, b]) > 1 || resume(n, v);
      });
    };
  }
  function resume(n, v) {
    try {
      step(g[n](v));
    } catch (e) {
      settle(q[0][3], e);
    }
  }
  function step(r) {
    r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
  }
  function fulfill(value) {
    resume("next", value);
  }
  function reject(value) {
    resume("throw", value);
  }
  function settle(f, v) {
    if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]);
  }
}
function __asyncDelegator(o) {
  var i, p;
  return i = {}, verb("next"), verb("throw", function(e) {
    throw e;
  }), verb("return"), i[Symbol.iterator] = function() {
    return this;
  }, i;
  function verb(n, f) {
    i[n] = o[n] ? function(v) {
      return (p = !p) ? { value: __await(o[n](v)), done: n === "return" } : f ? f(v) : v;
    } : f;
  }
}
function __asyncValues(o) {
  if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
  var m = o[Symbol.asyncIterator], i;
  return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
    return this;
  }, i);
  function verb(n) {
    i[n] = o[n] && function(v) {
      return new Promise(function(resolve, reject) {
        v = o[n](v), settle(resolve, reject, v.done, v.value);
      });
    };
  }
  function settle(resolve, reject, d, v) {
    Promise.resolve(v).then(function(v2) {
      resolve({ value: v2, done: d });
    }, reject);
  }
}
var ResultAsync = class _ResultAsync {
  constructor(res) {
    this._promise = res;
  }
  static fromSafePromise(promise) {
    const newPromise = promise.then((value) => new Ok(value));
    return new _ResultAsync(newPromise);
  }
  static fromPromise(promise, errorFn) {
    const newPromise = promise.then((value) => new Ok(value)).catch((e) => new Err(errorFn(e)));
    return new _ResultAsync(newPromise);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  static fromThrowable(fn, errorFn) {
    return (...args) => {
      return new _ResultAsync((() => __awaiter(this, void 0, void 0, function* () {
        try {
          return new Ok(yield fn(...args));
        } catch (error) {
          return new Err(errorFn ? errorFn(error) : error);
        }
      }))());
    };
  }
  static combine(asyncResultList) {
    return combineResultAsyncList(asyncResultList);
  }
  static combineWithAllErrors(asyncResultList) {
    return combineResultAsyncListWithAllErrors(asyncResultList);
  }
  map(f) {
    return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
      if (res.isErr()) {
        return new Err(res.error);
      }
      return new Ok(yield f(res.value));
    })));
  }
  andThrough(f) {
    return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
      if (res.isErr()) {
        return new Err(res.error);
      }
      const newRes = yield f(res.value);
      if (newRes.isErr()) {
        return new Err(newRes.error);
      }
      return new Ok(res.value);
    })));
  }
  andTee(f) {
    return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
      if (res.isErr()) {
        return new Err(res.error);
      }
      try {
        yield f(res.value);
      } catch (e) {
      }
      return new Ok(res.value);
    })));
  }
  mapErr(f) {
    return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
      if (res.isOk()) {
        return new Ok(res.value);
      }
      return new Err(yield f(res.error));
    })));
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  andThen(f) {
    return new _ResultAsync(this._promise.then((res) => {
      if (res.isErr()) {
        return new Err(res.error);
      }
      const newValue = f(res.value);
      return newValue instanceof _ResultAsync ? newValue._promise : newValue;
    }));
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  orElse(f) {
    return new _ResultAsync(this._promise.then((res) => __awaiter(this, void 0, void 0, function* () {
      if (res.isErr()) {
        return f(res.error);
      }
      return new Ok(res.value);
    })));
  }
  match(ok2, _err) {
    return this._promise.then((res) => res.match(ok2, _err));
  }
  unwrapOr(t) {
    return this._promise.then((res) => res.unwrapOr(t));
  }
  /**
   * Emulates Rust's `?` operator in `safeTry`'s body. See also `safeTry`.
   */
  safeUnwrap() {
    return __asyncGenerator(this, arguments, function* safeUnwrap_1() {
      return yield __await(yield __await(yield* __asyncDelegator(__asyncValues(yield __await(this._promise.then((res) => res.safeUnwrap()))))));
    });
  }
  // Makes ResultAsync implement PromiseLike<Result>
  then(successCallback, failureCallback) {
    return this._promise.then(successCallback, failureCallback);
  }
};
var errAsync = (err2) => new ResultAsync(Promise.resolve(new Err(err2)));
var fromPromise = ResultAsync.fromPromise;
var fromSafePromise = ResultAsync.fromSafePromise;
var fromAsyncThrowable = ResultAsync.fromThrowable;
var combineResultList = (resultList) => {
  let acc = ok([]);
  for (const result of resultList) {
    if (result.isErr()) {
      acc = err(result.error);
      break;
    } else {
      acc.map((list) => list.push(result.value));
    }
  }
  return acc;
};
var combineResultAsyncList = (asyncResultList) => ResultAsync.fromSafePromise(Promise.all(asyncResultList)).andThen(combineResultList);
var combineResultListWithAllErrors = (resultList) => {
  let acc = ok([]);
  for (const result of resultList) {
    if (result.isErr() && acc.isErr()) {
      acc.error.push(result.error);
    } else if (result.isErr() && acc.isOk()) {
      acc = err([result.error]);
    } else if (result.isOk() && acc.isOk()) {
      acc.value.push(result.value);
    }
  }
  return acc;
};
var combineResultAsyncListWithAllErrors = (asyncResultList) => ResultAsync.fromSafePromise(Promise.all(asyncResultList)).andThen(combineResultListWithAllErrors);
var Result;
(function(Result2) {
  function fromThrowable2(fn, errorFn) {
    return (...args) => {
      try {
        const result = fn(...args);
        return ok(result);
      } catch (e) {
        return err(errorFn ? errorFn(e) : e);
      }
    };
  }
  Result2.fromThrowable = fromThrowable2;
  function combine(resultList) {
    return combineResultList(resultList);
  }
  Result2.combine = combine;
  function combineWithAllErrors(resultList) {
    return combineResultListWithAllErrors(resultList);
  }
  Result2.combineWithAllErrors = combineWithAllErrors;
})(Result || (Result = {}));
var ok = (value) => new Ok(value);
function err(err2) {
  return new Err(err2);
}
var Ok = class {
  constructor(value) {
    this.value = value;
  }
  isOk() {
    return true;
  }
  isErr() {
    return !this.isOk();
  }
  map(f) {
    return ok(f(this.value));
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  mapErr(_f) {
    return ok(this.value);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  andThen(f) {
    return f(this.value);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  andThrough(f) {
    return f(this.value).map((_value) => this.value);
  }
  andTee(f) {
    try {
      f(this.value);
    } catch (e) {
    }
    return ok(this.value);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  orElse(_f) {
    return ok(this.value);
  }
  asyncAndThen(f) {
    return f(this.value);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  asyncAndThrough(f) {
    return f(this.value).map(() => this.value);
  }
  asyncMap(f) {
    return ResultAsync.fromSafePromise(f(this.value));
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  unwrapOr(_v) {
    return this.value;
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  match(ok2, _err) {
    return ok2(this.value);
  }
  safeUnwrap() {
    const value = this.value;
    return function* () {
      return value;
    }();
  }
  _unsafeUnwrap(_) {
    return this.value;
  }
  _unsafeUnwrapErr(config) {
    throw createNeverThrowError("Called `_unsafeUnwrapErr` on an Ok", this, config);
  }
};
var Err = class {
  constructor(error) {
    this.error = error;
  }
  isOk() {
    return false;
  }
  isErr() {
    return !this.isOk();
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  map(_f) {
    return err(this.error);
  }
  mapErr(f) {
    return err(f(this.error));
  }
  andThrough(_f) {
    return err(this.error);
  }
  andTee(_f) {
    return err(this.error);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  andThen(_f) {
    return err(this.error);
  }
  // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types
  orElse(f) {
    return f(this.error);
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  asyncAndThen(_f) {
    return errAsync(this.error);
  }
  asyncAndThrough(_f) {
    return errAsync(this.error);
  }
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  asyncMap(_f) {
    return errAsync(this.error);
  }
  unwrapOr(v) {
    return v;
  }
  match(_ok, err2) {
    return err2(this.error);
  }
  safeUnwrap() {
    const error = this.error;
    return function* () {
      yield err(error);
      throw new Error("Do not use this generator out of `safeTry`");
    }();
  }
  _unsafeUnwrap(config) {
    throw createNeverThrowError("Called `_unsafeUnwrap` on an Err", this, config);
  }
  _unsafeUnwrapErr(_) {
    return this.error;
  }
};
var fromThrowable = Result.fromThrowable;

// src/types.ts
var StepTypes = [
  "Initial",
  "Run",
  "SleepFor",
  "SleepUntil",
  "Call",
  "Wait",
  "Notify",
  "Invoke"
];

// src/workflow-requests.ts
var import_qstash3 = require("@upstash/qstash");
var triggerFirstInvocation = async ({
  workflowContext,
  useJSONContent,
  telemetry,
  debug,
  invokeCount
}) => {
  const { headers } = getHeaders({
    initHeaderValue: "true",
    workflowRunId: workflowContext.workflowRunId,
    workflowUrl: workflowContext.url,
    userHeaders: workflowContext.headers,
    failureUrl: workflowContext.failureUrl,
    retries: workflowContext.retries,
    telemetry,
    invokeCount,
    flowControl: workflowContext.flowControl
  });
  if (workflowContext.headers.get("content-type")) {
    headers["content-type"] = workflowContext.headers.get("content-type");
  }
  if (useJSONContent) {
    headers["content-type"] = "application/json";
  }
  try {
    const body = typeof workflowContext.requestPayload === "string" ? workflowContext.requestPayload : JSON.stringify(workflowContext.requestPayload);
    const result = await workflowContext.qstashClient.publish({
      headers,
      method: "POST",
      body,
      url: workflowContext.url
    });
    if (result.deduplicated) {
      await debug?.log("WARN", "SUBMIT_FIRST_INVOCATION", {
        message: `Workflow run ${workflowContext.workflowRunId} already exists. A new one isn't created.`,
        headers,
        requestPayload: workflowContext.requestPayload,
        url: workflowContext.url,
        messageId: result.messageId
      });
      return ok("workflow-run-already-exists");
    } else {
      await debug?.log("SUBMIT", "SUBMIT_FIRST_INVOCATION", {
        headers,
        requestPayload: workflowContext.requestPayload,
        url: workflowContext.url,
        messageId: result.messageId
      });
      return ok("success");
    }
  } catch (error) {
    const error_ = error;
    return err(error_);
  }
};
var triggerRouteFunction = async ({
  onCleanup,
  onStep,
  onCancel,
  debug
}) => {
  try {
    const result = await onStep();
    await onCleanup(result);
    return ok("workflow-finished");
  } catch (error) {
    const error_ = error;
    if (error instanceof import_qstash3.QstashError && error.status === 400) {
      await debug?.log("WARN", "RESPONSE_WORKFLOW", {
        message: `tried to append to a cancelled workflow. exiting without publishing.`,
        name: error.name,
        errorMessage: error.message
      });
      return ok("workflow-was-finished");
    } else if (!(error_ instanceof WorkflowAbort)) {
      return err(error_);
    } else if (error_.cancelWorkflow) {
      await onCancel();
      return ok("workflow-finished");
    } else {
      return ok("step-finished");
    }
  }
};
var triggerWorkflowDelete = async (workflowContext, result, debug, cancel = false) => {
  await debug?.log("SUBMIT", "SUBMIT_CLEANUP", {
    deletedWorkflowRunId: workflowContext.workflowRunId
  });
  await workflowContext.qstashClient.http.request({
    path: ["v2", "workflows", "runs", `${workflowContext.workflowRunId}?cancel=${cancel}`],
    method: "DELETE",
    parseResponseAsJson: false,
    body: JSON.stringify(result)
  });
  await debug?.log(
    "SUBMIT",
    "SUBMIT_CLEANUP",
    `workflow run ${workflowContext.workflowRunId} deleted.`
  );
};
var recreateUserHeaders = (headers) => {
  const filteredHeaders = new Headers();
  const pairs = headers.entries();
  for (const [header, value] of pairs) {
    const headerLowerCase = header.toLowerCase();
    if (!headerLowerCase.startsWith("upstash-workflow-") && // https://vercel.com/docs/edge-network/headers/request-headers#x-vercel-id
    !headerLowerCase.startsWith("x-vercel-") && !headerLowerCase.startsWith("x-forwarded-") && // https://blog.cloudflare.com/preventing-request-loops-using-cdn-loop/
    headerLowerCase !== "cf-connecting-ip" && headerLowerCase !== "cdn-loop" && headerLowerCase !== "cf-ew-via" && headerLowerCase !== "cf-ray" && // For Render https://render.com
    headerLowerCase !== "render-proxy-ttl") {
      filteredHeaders.append(header, value);
    }
  }
  return filteredHeaders;
};
var handleThirdPartyCallResult = async ({
  request,
  requestPayload,
  client,
  workflowUrl,
  failureUrl,
  retries,
  telemetry,
  flowControl,
  debug
}) => {
  try {
    if (request.headers.get("Upstash-Workflow-Callback")) {
      let callbackPayload;
      if (requestPayload) {
        callbackPayload = requestPayload;
      } else {
        const workflowRunId2 = request.headers.get("upstash-workflow-runid");
        const messageId = request.headers.get("upstash-message-id");
        if (!workflowRunId2)
          throw new WorkflowError("workflow run id missing in context.call lazy fetch.");
        if (!messageId) throw new WorkflowError("message id missing in context.call lazy fetch.");
        const { steps, workflowRunEnded } = await getSteps(
          client.http,
          workflowRunId2,
          messageId,
          debug
        );
        if (workflowRunEnded) {
          return ok("workflow-ended");
        }
        const failingStep = steps.find((step) => step.messageId === messageId);
        if (!failingStep)
          throw new WorkflowError(
            "Failed to submit the context.call. " + (steps.length === 0 ? "No steps found." : `No step was found with matching messageId ${messageId} out of ${steps.length} steps.`)
          );
        callbackPayload = atob(failingStep.body);
      }
      const callbackMessage = JSON.parse(callbackPayload);
      if (!(callbackMessage.status >= 200 && callbackMessage.status < 300) && callbackMessage.maxRetries && callbackMessage.retried !== callbackMessage.maxRetries) {
        await debug?.log("WARN", "SUBMIT_THIRD_PARTY_RESULT", {
          status: callbackMessage.status,
          body: atob(callbackMessage.body ?? "")
        });
        console.warn(
          `Workflow Warning: "context.call" failed with status ${callbackMessage.status} and will retry (retried ${callbackMessage.retried ?? 0} out of ${callbackMessage.maxRetries} times). Error Message:
${atob(callbackMessage.body ?? "")}`
        );
        return ok("call-will-retry");
      }
      const workflowRunId = request.headers.get(WORKFLOW_ID_HEADER);
      const stepIdString = request.headers.get("Upstash-Workflow-StepId");
      const stepName = request.headers.get("Upstash-Workflow-StepName");
      const stepType = request.headers.get("Upstash-Workflow-StepType");
      const concurrentString = request.headers.get("Upstash-Workflow-Concurrent");
      const contentType = request.headers.get("Upstash-Workflow-ContentType");
      const invokeCount = request.headers.get(WORKFLOW_INVOKE_COUNT_HEADER);
      if (!(workflowRunId && stepIdString && stepName && StepTypes.includes(stepType) && concurrentString && contentType)) {
        throw new Error(
          `Missing info in callback message source header: ${JSON.stringify({
            workflowRunId,
            stepIdString,
            stepName,
            stepType,
            concurrentString,
            contentType
          })}`
        );
      }
      const userHeaders = recreateUserHeaders(request.headers);
      const { headers: requestHeaders } = getHeaders({
        initHeaderValue: "false",
        workflowRunId,
        workflowUrl,
        userHeaders,
        failureUrl,
        retries,
        telemetry,
        invokeCount: Number(invokeCount),
        flowControl
      });
      const callResponse = {
        status: callbackMessage.status,
        body: atob(callbackMessage.body ?? ""),
        header: callbackMessage.header
      };
      const callResultStep = {
        stepId: Number(stepIdString),
        stepName,
        stepType,
        out: JSON.stringify(callResponse),
        concurrent: Number(concurrentString)
      };
      await debug?.log("SUBMIT", "SUBMIT_THIRD_PARTY_RESULT", {
        step: callResultStep,
        headers: requestHeaders,
        url: workflowUrl
      });
      const result = await client.publishJSON({
        headers: requestHeaders,
        method: "POST",
        body: callResultStep,
        url: workflowUrl
      });
      await debug?.log("SUBMIT", "SUBMIT_THIRD_PARTY_RESULT", {
        messageId: result.messageId
      });
      return ok("is-call-return");
    } else {
      return ok("continue-workflow");
    }
  } catch (error) {
    const isCallReturn = request.headers.get("Upstash-Workflow-Callback");
    return err(
      new WorkflowError(`Error when handling call return (isCallReturn=${isCallReturn}): ${error}`)
    );
  }
};
var getTelemetryHeaders = (telemetry) => {
  return {
    [TELEMETRY_HEADER_SDK]: telemetry.sdk,
    [TELEMETRY_HEADER_FRAMEWORK]: telemetry.framework,
    [TELEMETRY_HEADER_RUNTIME]: telemetry.runtime ?? "unknown"
  };
};
var getHeaders = ({
  initHeaderValue,
  workflowRunId,
  workflowUrl,
  userHeaders,
  failureUrl,
  retries,
  step,
  callRetries,
  callTimeout,
  telemetry,
  invokeCount,
  flowControl,
  callFlowControl
}) => {
  const callHeaders = new Headers(step?.callHeaders);
  const contentType = (callHeaders.get("content-type") ? callHeaders.get("content-type") : userHeaders?.get("Content-Type") ? userHeaders.get("Content-Type") : void 0) ?? DEFAULT_CONTENT_TYPE;
  const baseHeaders = {
    [WORKFLOW_INIT_HEADER]: initHeaderValue,
    [WORKFLOW_ID_HEADER]: workflowRunId,
    [WORKFLOW_URL_HEADER]: workflowUrl,
    [WORKFLOW_FEATURE_HEADER]: "LazyFetch,InitialBody",
    [WORKFLOW_PROTOCOL_VERSION_HEADER]: WORKFLOW_PROTOCOL_VERSION,
    "content-type": contentType,
    ...telemetry ? getTelemetryHeaders(telemetry) : {}
  };
  if (invokeCount !== void 0 && !step?.callUrl) {
    baseHeaders[`Upstash-Forward-${WORKFLOW_INVOKE_COUNT_HEADER}`] = invokeCount.toString();
  }
  if (!step?.callUrl) {
    baseHeaders[`Upstash-Forward-${WORKFLOW_PROTOCOL_VERSION_HEADER}`] = WORKFLOW_PROTOCOL_VERSION;
  }
  if (callTimeout) {
    baseHeaders[`Upstash-Timeout`] = callTimeout.toString();
  }
  if (failureUrl) {
    baseHeaders[`Upstash-Failure-Callback-Forward-${WORKFLOW_FAILURE_HEADER}`] = "true";
    baseHeaders[`Upstash-Failure-Callback-Forward-Upstash-Workflow-Failure-Callback`] = "true";
    baseHeaders["Upstash-Failure-Callback-Workflow-Runid"] = workflowRunId;
    baseHeaders["Upstash-Failure-Callback-Workflow-Init"] = "false";
    baseHeaders["Upstash-Failure-Callback-Workflow-Url"] = workflowUrl;
    baseHeaders["Upstash-Failure-Callback-Workflow-Calltype"] = "failureCall";
    if (retries !== void 0) {
      baseHeaders["Upstash-Failure-Callback-Retries"] = retries.toString();
    }
    if (flowControl) {
      const { flowControlKey, flowControlValue } = prepareFlowControl(flowControl);
      baseHeaders["Upstash-Failure-Callback-Flow-Control-Key"] = flowControlKey;
      baseHeaders["Upstash-Failure-Callback-Flow-Control-Value"] = flowControlValue;
    }
    if (!step?.callUrl) {
      baseHeaders["Upstash-Failure-Callback"] = failureUrl;
    }
  }
  if (step?.callUrl) {
    baseHeaders["Upstash-Retries"] = callRetries?.toString() ?? "0";
    baseHeaders[WORKFLOW_FEATURE_HEADER] = "WF_NoDelete,InitialBody";
    if (retries !== void 0) {
      baseHeaders["Upstash-Callback-Retries"] = retries.toString();
      baseHeaders["Upstash-Failure-Callback-Retries"] = retries.toString();
    }
    if (callFlowControl) {
      const { flowControlKey, flowControlValue } = prepareFlowControl(callFlowControl);
      baseHeaders["Upstash-Flow-Control-Key"] = flowControlKey;
      baseHeaders["Upstash-Flow-Control-Value"] = flowControlValue;
    }
    if (flowControl) {
      const { flowControlKey, flowControlValue } = prepareFlowControl(flowControl);
      baseHeaders["Upstash-Callback-Flow-Control-Key"] = flowControlKey;
      baseHeaders["Upstash-Callback-Flow-Control-Value"] = flowControlValue;
    }
  } else {
    if (flowControl) {
      const { flowControlKey, flowControlValue } = prepareFlowControl(flowControl);
      baseHeaders["Upstash-Flow-Control-Key"] = flowControlKey;
      baseHeaders["Upstash-Flow-Control-Value"] = flowControlValue;
    }
    if (retries !== void 0) {
      baseHeaders["Upstash-Retries"] = retries.toString();
      baseHeaders["Upstash-Failure-Callback-Retries"] = retries.toString();
    }
  }
  if (userHeaders) {
    for (const header of userHeaders.keys()) {
      if (step?.callHeaders) {
        baseHeaders[`Upstash-Callback-Forward-${header}`] = userHeaders.get(header);
      } else {
        baseHeaders[`Upstash-Forward-${header}`] = userHeaders.get(header);
      }
      baseHeaders[`Upstash-Failure-Callback-Forward-${header}`] = userHeaders.get(header);
    }
  }
  if (step?.callHeaders) {
    const forwardedHeaders = Object.fromEntries(
      Object.entries(step.callHeaders).map(([header, value]) => [
        `Upstash-Forward-${header}`,
        value
      ])
    );
    return {
      headers: {
        ...baseHeaders,
        ...forwardedHeaders,
        "Upstash-Callback": workflowUrl,
        "Upstash-Callback-Workflow-RunId": workflowRunId,
        "Upstash-Callback-Workflow-CallType": "fromCallback",
        "Upstash-Callback-Workflow-Init": "false",
        "Upstash-Callback-Workflow-Url": workflowUrl,
        "Upstash-Callback-Feature-Set": "LazyFetch,InitialBody",
        "Upstash-Callback-Forward-Upstash-Workflow-Callback": "true",
        "Upstash-Callback-Forward-Upstash-Workflow-StepId": step.stepId.toString(),
        "Upstash-Callback-Forward-Upstash-Workflow-StepName": step.stepName,
        "Upstash-Callback-Forward-Upstash-Workflow-StepType": step.stepType,
        "Upstash-Callback-Forward-Upstash-Workflow-Concurrent": step.concurrent.toString(),
        "Upstash-Callback-Forward-Upstash-Workflow-ContentType": contentType,
        [`Upstash-Callback-Forward-${WORKFLOW_INVOKE_COUNT_HEADER}`]: (invokeCount ?? 0).toString(),
        "Upstash-Workflow-CallType": "toCallback"
      }
    };
  }
  if (step?.waitEventId) {
    return {
      headers: {
        ...baseHeaders,
        "Upstash-Workflow-CallType": "step"
      },
      timeoutHeaders: {
        // to include user headers:
        ...Object.fromEntries(
          Object.entries(baseHeaders).map(([header, value]) => [header, [value]])
        ),
        // to include telemetry headers:
        ...telemetry ? Object.fromEntries(
          Object.entries(getTelemetryHeaders(telemetry)).map(([header, value]) => [
            header,
            [value]
          ])
        ) : {},
        // note: using WORKFLOW_ID_HEADER doesn't work, because Runid -> RunId:
        "Upstash-Workflow-Runid": [workflowRunId],
        [WORKFLOW_INIT_HEADER]: ["false"],
        [WORKFLOW_URL_HEADER]: [workflowUrl],
        "Upstash-Workflow-CallType": ["step"]
      }
    };
  }
  return { headers: baseHeaders };
};
var verifyRequest = async (body, signature, verifier) => {
  if (!verifier) {
    return;
  }
  try {
    if (!signature) {
      throw new Error("`Upstash-Signature` header is not passed.");
    }
    const isValid = await verifier.verify({
      body,
      signature
    });
    if (!isValid) {
      throw new Error("Signature in `Upstash-Signature` header is not valid");
    }
  } catch (error) {
    throw new WorkflowError(
      `Failed to verify that the Workflow request comes from QStash: ${error}

If signature is missing, trigger the workflow endpoint by publishing your request to QStash instead of calling it directly.

If you want to disable QStash Verification, you should clear env variables QSTASH_CURRENT_SIGNING_KEY and QSTASH_NEXT_SIGNING_KEY`
    );
  }
};
var prepareFlowControl = (flowControl) => {
  const parallelism = flowControl.parallelism?.toString();
  const rate = flowControl.ratePerSecond?.toString();
  const controlValue = [
    parallelism ? `parallelism=${parallelism}` : void 0,
    rate ? `rate=${rate}` : void 0
  ].filter(Boolean);
  if (controlValue.length === 0) {
    throw new import_qstash3.QstashError("Provide at least one of parallelism or ratePerSecond for flowControl");
  }
  return {
    flowControlKey: flowControl.key,
    flowControlValue: controlValue.join(", ")
  };
};

// src/context/auto-executor.ts
var import_qstash4 = require("@upstash/qstash");

// src/serve/serve-many.ts
var invokeWorkflow = async ({
  settings,
  invokeStep,
  context,
  invokeCount,
  telemetry
}) => {
  const {
    body,
    workflow,
    headers = {},
    workflowRunId = getWorkflowRunId(),
    retries,
    flowControl
  } = settings;
  const { workflowId } = workflow;
  const {
    retries: workflowRetries,
    failureFunction,
    failureUrl,
    useJSONContent,
    flowControl: workflowFlowControl
  } = workflow.options;
  if (!workflowId) {
    throw new WorkflowError("You can only invoke workflow which has a workflowId");
  }
  const { headers: invokerHeaders } = getHeaders({
    initHeaderValue: "false",
    workflowRunId: context.workflowRunId,
    workflowUrl: context.url,
    userHeaders: context.headers,
    failureUrl: context.failureUrl,
    retries: context.retries,
    telemetry,
    invokeCount,
    flowControl: context.flowControl
  });
  invokerHeaders["Upstash-Workflow-Runid"] = context.workflowRunId;
  const newUrl = context.url.replace(/[^/]+$/, workflowId);
  const { headers: triggerHeaders } = getHeaders({
    initHeaderValue: "true",
    workflowRunId,
    workflowUrl: newUrl,
    userHeaders: new Headers(headers),
    retries: retries ?? workflowRetries,
    telemetry,
    failureUrl: failureFunction ? newUrl : failureUrl,
    invokeCount: invokeCount + 1,
    flowControl: flowControl ?? workflowFlowControl
  });
  triggerHeaders["Upstash-Workflow-Invoke"] = "true";
  if (useJSONContent) {
    triggerHeaders["content-type"] = "application/json";
  }
  const request = {
    body: JSON.stringify(body),
    headers: Object.fromEntries(
      Object.entries(invokerHeaders).map((pairs) => [pairs[0], [pairs[1]]])
    ),
    workflowRunId: context.workflowRunId,
    workflowUrl: context.url,
    step: invokeStep
  };
  await context.qstashClient.publish({
    headers: triggerHeaders,
    method: "POST",
    body: JSON.stringify(request),
    url: newUrl
  });
};

// src/context/auto-executor.ts
var AutoExecutor = class _AutoExecutor {
  context;
  promises = /* @__PURE__ */ new WeakMap();
  activeLazyStepList;
  debug;
  nonPlanStepCount;
  steps;
  indexInCurrentList = 0;
  invokeCount;
  telemetry;
  stepCount = 0;
  planStepCount = 0;
  executingStep = false;
  constructor(context, steps, telemetry, invokeCount, debug) {
    this.context = context;
    this.steps = steps;
    this.telemetry = telemetry;
    this.invokeCount = invokeCount ?? 0;
    this.debug = debug;
    this.nonPlanStepCount = this.steps.filter((step) => !step.targetStep).length;
  }
  /**
   * Adds the step function to the list of step functions to run in
   * parallel. After adding the function, defers the execution, so
   * that if there is another step function to be added, it's also
   * added.
   *
   * After all functions are added, list of functions are executed.
   * If there is a single function, it's executed by itself. If there
   * are multiple, they are run in parallel.
   *
   * If a function is already executing (this.executingStep), this
   * means that there is a nested step which is not allowed. In this
   * case, addStep throws WorkflowError.
   *
   * @param stepInfo step plan to add
   * @returns result of the step function
   */
  async addStep(stepInfo) {
    if (this.executingStep) {
      throw new WorkflowError(
        `A step can not be run inside another step. Tried to run '${stepInfo.stepName}' inside '${this.executingStep}'`
      );
    }
    this.stepCount += 1;
    const lazyStepList = this.activeLazyStepList ?? [];
    if (!this.activeLazyStepList) {
      this.activeLazyStepList = lazyStepList;
      this.indexInCurrentList = 0;
    }
    lazyStepList.push(stepInfo);
    const index = this.indexInCurrentList++;
    const requestComplete = this.deferExecution().then(async () => {
      if (!this.promises.has(lazyStepList)) {
        const promise2 = this.getExecutionPromise(lazyStepList);
        this.promises.set(lazyStepList, promise2);
        this.activeLazyStepList = void 0;
        this.planStepCount += lazyStepList.length > 1 ? lazyStepList.length : 0;
      }
      const promise = this.promises.get(lazyStepList);
      return promise;
    });
    const result = await requestComplete;
    return _AutoExecutor.getResult(lazyStepList, result, index);
  }
  /**
   * Wraps a step function to set this.executingStep to step name
   * before running and set this.executingStep to False after execution
   * ends.
   *
   * this.executingStep allows us to detect nested steps which are not
   * allowed.
   *
   * @param stepName name of the step being wrapped
   * @param stepFunction step function to wrap
   * @returns wrapped step function
   */
  wrapStep(stepName, stepFunction) {
    this.executingStep = stepName;
    const result = stepFunction();
    this.executingStep = false;
    return result;
  }
  /**
   * Executes a step:
   * - If the step result is available in the steps, returns the result
   * - If the result is not avaiable, runs the function
   * - Sends the result to QStash
   *
   * @param lazyStep lazy step to execute
   * @returns step result
   */
  async runSingle(lazyStep) {
    if (this.stepCount < this.nonPlanStepCount) {
      const step = this.steps[this.stepCount + this.planStepCount];
      validateStep(lazyStep, step);
      await this.debug?.log("INFO", "RUN_SINGLE", {
        fromRequest: true,
        step,
        stepCount: this.stepCount
      });
      return lazyStep.parseOut(step.out);
    }
    const resultStep = await lazyStep.getResultStep(NO_CONCURRENCY, this.stepCount);
    await this.debug?.log("INFO", "RUN_SINGLE", {
      fromRequest: false,
      step: resultStep,
      stepCount: this.stepCount
    });
    await this.submitStepsToQStash([resultStep], [lazyStep]);
    return resultStep.out;
  }
  /**
   * Runs steps in parallel.
   *
   * @param stepName parallel step name
   * @param stepFunctions list of async functions to run in parallel
   * @returns results of the functions run in parallel
   */
  async runParallel(parallelSteps) {
    const initialStepCount = this.stepCount - (parallelSteps.length - 1);
    const parallelCallState = this.getParallelCallState(parallelSteps.length, initialStepCount);
    const sortedSteps = sortSteps(this.steps);
    const plannedParallelStepCount = sortedSteps[initialStepCount + this.planStepCount]?.concurrent;
    if (parallelCallState !== "first" && plannedParallelStepCount !== parallelSteps.length) {
      throw new WorkflowError(
        `Incompatible number of parallel steps when call state was '${parallelCallState}'. Expected ${parallelSteps.length}, got ${plannedParallelStepCount} from the request.`
      );
    }
    await this.debug?.log("INFO", "RUN_PARALLEL", {
      parallelCallState,
      initialStepCount,
      plannedParallelStepCount,
      stepCount: this.stepCount,
      planStepCount: this.planStepCount
    });
    switch (parallelCallState) {
      case "first": {
        const planSteps = parallelSteps.map(
          (parallelStep, index) => parallelStep.getPlanStep(parallelSteps.length, initialStepCount + index)
        );
        await this.submitStepsToQStash(planSteps, parallelSteps);
        break;
      }
      case "partial": {
        const planStep = this.steps.at(-1);
        if (!planStep || planStep.targetStep === void 0) {
          throw new WorkflowError(
            `There must be a last step and it should have targetStep larger than 0.Received: ${JSON.stringify(planStep)}`
          );
        }
        const stepIndex = planStep.targetStep - initialStepCount;
        validateStep(parallelSteps[stepIndex], planStep);
        try {
          const parallelStep = parallelSteps[stepIndex];
          const resultStep = await parallelStep.getResultStep(
            parallelSteps.length,
            planStep.targetStep
          );
          await this.submitStepsToQStash([resultStep], [parallelStep]);
        } catch (error) {
          if (error instanceof WorkflowAbort || error instanceof import_qstash4.QstashError && error.status === 400) {
            throw error;
          }
          throw new WorkflowError(
            `Error submitting steps to QStash in partial parallel step execution: ${error}`
          );
        }
        break;
      }
      case "discard": {
        throw new WorkflowAbort("discarded parallel");
      }
      case "last": {
        const parallelResultSteps = sortedSteps.filter((step) => step.stepId >= initialStepCount).slice(0, parallelSteps.length);
        validateParallelSteps(parallelSteps, parallelResultSteps);
        return parallelResultSteps.map(
          (step, index) => parallelSteps[index].parseOut(step.out)
        );
      }
    }
    const fillValue = void 0;
    return Array.from({ length: parallelSteps.length }).fill(fillValue);
  }
  /**
   * Determines the parallel call state
   *
   * First filters the steps to get the steps which are after `initialStepCount` parameter.
   *
   * Depending on the remaining steps, decides the parallel state:
   * - "first": If there are no steps
   * - "last" If there are equal to or more than `2 * parallelStepCount`. We multiply by two
   *   because each step in a parallel execution will have 2 steps: a plan step and a result
   *   step.
   * - "partial": If the last step is a plan step
   * - "discard": If the last step is not a plan step. This means that the parallel execution
   *   is in progress (there are still steps to run) and one step has finished and submitted
   *   its result to QStash
   *
   * @param parallelStepCount number of steps to run in parallel
   * @param initialStepCount steps after the parallel invocation
   * @returns parallel call state
   */
  getParallelCallState(parallelStepCount, initialStepCount) {
    const remainingSteps = this.steps.filter(
      (step) => (step.targetStep || step.stepId) >= initialStepCount
    );
    if (remainingSteps.length === 0) {
      return "first";
    } else if (remainingSteps.length >= 2 * parallelStepCount) {
      return "last";
    } else if (remainingSteps.at(-1)?.targetStep) {
      return "partial";
    } else {
      return "discard";
    }
  }
  /**
   * sends the steps to QStash as batch
   *
   * @param steps steps to send
   */
  async submitStepsToQStash(steps, lazySteps) {
    if (steps.length === 0) {
      throw new WorkflowError(
        `Unable to submit steps to QStash. Provided list is empty. Current step: ${this.stepCount}`
      );
    }
    await this.debug?.log("SUBMIT", "SUBMIT_STEP", {
      length: steps.length,
      steps
    });
    if (steps[0].waitEventId && steps.length === 1) {
      const waitStep = steps[0];
      const { headers, timeoutHeaders } = getHeaders({
        initHeaderValue: "false",
        workflowRunId: this.context.workflowRunId,
        workflowUrl: this.context.url,
        userHeaders: this.context.headers,
        step: waitStep,
        failureUrl: this.context.failureUrl,
        retries: this.context.retries,
        telemetry: this.telemetry,
        invokeCount: this.invokeCount,
        flowControl: this.context.flowControl
      });
      const waitBody = {
        url: this.context.url,
        timeout: waitStep.timeout,
        timeoutBody: void 0,
        timeoutUrl: this.context.url,
        timeoutHeaders,
        step: {
          stepId: waitStep.stepId,
          stepType: "Wait",
          stepName: waitStep.stepName,
          concurrent: waitStep.concurrent,
          targetStep: waitStep.targetStep
        }
      };
      await this.context.qstashClient.http.request({
        path: ["v2", "wait", waitStep.waitEventId],
        body: JSON.stringify(waitBody),
        headers,
        method: "POST",
        parseResponseAsJson: false
      });
      throw new WorkflowAbort(waitStep.stepName, waitStep);
    }
    if (steps.length === 1 && lazySteps[0] instanceof LazyInvokeStep) {
      const invokeStep = steps[0];
      const lazyInvokeStep = lazySteps[0];
      await invokeWorkflow({
        settings: lazyInvokeStep.params,
        invokeStep,
        context: this.context,
        invokeCount: this.invokeCount,
        telemetry: this.telemetry
      });
      throw new WorkflowAbort(invokeStep.stepName, invokeStep);
    }
    const result = await this.context.qstashClient.batch(
      steps.map((singleStep, index) => {
        const lazyStep = lazySteps[index];
        const { headers } = getHeaders({
          initHeaderValue: "false",
          workflowRunId: this.context.workflowRunId,
          workflowUrl: this.context.url,
          userHeaders: this.context.headers,
          step: singleStep,
          failureUrl: this.context.failureUrl,
          retries: this.context.retries,
          callRetries: lazyStep instanceof LazyCallStep ? lazyStep.retries : void 0,
          callTimeout: lazyStep instanceof LazyCallStep ? lazyStep.timeout : void 0,
          telemetry: this.telemetry,
          invokeCount: this.invokeCount,
          flowControl: this.context.flowControl,
          callFlowControl: lazyStep instanceof LazyCallStep ? lazyStep.flowControl : void 0
        });
        const willWait = singleStep.concurrent === NO_CONCURRENCY || singleStep.stepId === 0;
        singleStep.out = JSON.stringify(singleStep.out);
        return singleStep.callUrl && lazyStep instanceof LazyCallStep ? (
          // if the step is a third party call, we call the third party
          // url (singleStep.callUrl) and pass information about the workflow
          // in the headers (handled in getHeaders). QStash makes the request
          // to callUrl and returns the result to Workflow endpoint.
          // handleThirdPartyCallResult method sends the result of the third
          // party call to QStash.
          {
            headers,
            method: singleStep.callMethod,
            body: JSON.stringify(singleStep.callBody),
            url: singleStep.callUrl
          }
        ) : (
          // if the step is not a third party call, we use workflow
          // endpoint (context.url) as URL when calling QStash. QStash
          // calls us back with the updated steps list.
          {
            headers,
            method: "POST",
            body: JSON.stringify(singleStep),
            url: this.context.url,
            notBefore: willWait ? singleStep.sleepUntil : void 0,
            delay: willWait ? singleStep.sleepFor : void 0
          }
        );
      })
    );
    const _result = result;
    await this.debug?.log("INFO", "SUBMIT_STEP", {
      messageIds: _result.map((message) => {
        return {
          message: message.messageId
        };
      })
    });
    throw new WorkflowAbort(steps[0].stepName, steps[0]);
  }
  /**
   * Get the promise by executing the lazt steps list. If there is a single
   * step, we call `runSingle`. Otherwise `runParallel` is called.
   *
   * @param lazyStepList steps list to execute
   * @returns promise corresponding to the execution
   */
  getExecutionPromise(lazyStepList) {
    return lazyStepList.length === 1 ? this.runSingle(lazyStepList[0]) : this.runParallel(lazyStepList);
  }
  /**
   * @param lazyStepList steps we executed
   * @param result result of the promise from `getExecutionPromise`
   * @param index index of the current step
   * @returns result[index] if lazyStepList > 1, otherwise result
   */
  // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-parameters
  static getResult(lazyStepList, result, index) {
    if (lazyStepList.length === 1) {
      return result;
    } else if (Array.isArray(result) && lazyStepList.length === result.length && index < lazyStepList.length) {
      return result[index];
    } else {
      throw new WorkflowError(
        `Unexpected parallel call result while executing step ${index}: '${result}'. Expected ${lazyStepList.length} many items`
      );
    }
  }
  async deferExecution() {
    await Promise.resolve();
    await Promise.resolve();
  }
};
var validateStep = (lazyStep, stepFromRequest) => {
  if (lazyStep.stepName !== stepFromRequest.stepName) {
    throw new WorkflowError(
      `Incompatible step name. Expected '${lazyStep.stepName}', got '${stepFromRequest.stepName}' from the request`
    );
  }
  if (lazyStep.stepType !== stepFromRequest.stepType) {
    throw new WorkflowError(
      `Incompatible step type. Expected '${lazyStep.stepType}', got '${stepFromRequest.stepType}' from the request`
    );
  }
};
var validateParallelSteps = (lazySteps, stepsFromRequest) => {
  try {
    for (const [index, stepFromRequest] of stepsFromRequest.entries()) {
      validateStep(lazySteps[index], stepFromRequest);
    }
  } catch (error) {
    if (error instanceof WorkflowError) {
      const lazyStepNames = lazySteps.map((lazyStep) => lazyStep.stepName);
      const lazyStepTypes = lazySteps.map((lazyStep) => lazyStep.stepType);
      const requestStepNames = stepsFromRequest.map((step) => step.stepName);
      const requestStepTypes = stepsFromRequest.map((step) => step.stepType);
      throw new WorkflowError(
        `Incompatible steps detected in parallel execution: ${error.message}
  > Step Names from the request: ${JSON.stringify(requestStepNames)}
    Step Types from the request: ${JSON.stringify(requestStepTypes)}
  > Step Names expected: ${JSON.stringify(lazyStepNames)}
    Step Types expected: ${JSON.stringify(lazyStepTypes)}`
      );
    }
    throw error;
  }
};
var sortSteps = (steps) => {
  const getStepId = (step) => step.targetStep || step.stepId;
  return [...steps].sort((step, stepOther) => getStepId(step) - getStepId(stepOther));
};

// src/context/api/anthropic.ts
var import_qstash5 = require("@upstash/qstash");

// src/context/provider.ts
var getProviderInfo = (api) => {
  if (!api.provider) {
    throw new WorkflowError("A Provider must be provided.");
  }
  if (api.provider.owner === "upstash") {
    throw new WorkflowError("Upstash provider isn't supported.");
  }
  const { name, provider, ...parameters } = api;
  if (!provider.baseUrl) throw new TypeError("baseUrl cannot be empty or undefined!");
  if (!provider.token) throw new TypeError("token cannot be empty or undefined!");
  if (provider.apiKind !== name) {
    throw new TypeError(`Unexpected api name. Expected '${provider.apiKind}', received ${name}`);
  }
  const providerInfo = {
    url: provider.getUrl(),
    baseUrl: provider.baseUrl,
    route: provider.getRoute(),
    appendHeaders: provider.getHeaders(parameters),
    owner: provider.owner,
    method: provider.method
  };
  return provider.onFinish(providerInfo, parameters);
};

// src/context/api/base.ts
var BaseWorkflowApi = class {
  context;
  constructor({ context }) {
    this.context = context;
  }
  /**
   * context.call which uses a QStash API
   *
   * @param stepName
   * @param settings
   * @returns
   */
  async callApi(stepName, settings) {
    const { url, appendHeaders, method } = getProviderInfo(settings.api);
    const { method: userMethod, body, headers = {}, retries = 0, timeout } = settings;
    return await this.context.call(stepName, {
      url,
      method: userMethod ?? method,
      body,
      headers: {
        ...appendHeaders,
        ...headers
      },
      retries,
      timeout
    });
  }
};

// src/context/api/anthropic.ts
var AnthropicAPI = class extends BaseWorkflowApi {
  async call(stepName, settings) {
    const { token, operation, ...parameters } = settings;
    return await this.callApi(stepName, {
      api: {
        name: "llm",
        provider: (0, import_qstash5.anthropic)({ token })
      },
      ...parameters
    });
  }
};

// src/context/api/openai.ts
var import_qstash6 = require("@upstash/qstash");
var OpenAIAPI = class extends BaseWorkflowApi {
  async call(stepName, settings) {
    const { token, organization, operation, baseURL, ...parameters } = settings;
    const useOpenAI = baseURL === void 0;
    const provider = useOpenAI ? (0, import_qstash6.openai)({ token, organization }) : (0, import_qstash6.custom)({ baseUrl: baseURL, token });
    return await this.callApi(stepName, {
      api: {
        name: "llm",
        provider
      },
      ...parameters
    });
  }
};

// src/context/api/resend.ts
var import_qstash7 = require("@upstash/qstash");
var ResendAPI = class extends BaseWorkflowApi {
  async call(stepName, settings) {
    const { token, batch = false, ...parameters } = settings;
    return await this.callApi(stepName, {
      api: {
        name: "email",
        provider: (0, import_qstash7.resend)({ token, batch })
      },
      ...parameters
    });
  }
};

// src/context/api/index.ts
var WorkflowApi = class extends BaseWorkflowApi {
  get openai() {
    return new OpenAIAPI({
      context: this.context
    });
  }
  get resend() {
    return new ResendAPI({
      context: this.context
    });
  }
  get anthropic() {
    return new AnthropicAPI({
      context: this.context
    });
  }
};

// src/agents/index.ts
var import_openai3 = require("@ai-sdk/openai");

// src/agents/adapters.ts
var import_openai2 = require("@ai-sdk/openai");
var import_ai = require("ai");

// src/agents/constants.ts
var AGENT_NAME_HEADER = "upstash-agent-name";
var MANAGER_AGENT_PROMPT = `You are an agent orchestrating other AI Agents.

These other agents have tools available to them.

Given a prompt, utilize these agents to address requests.

Don't always call all the agents provided to you at the same time. You can call one and use it's response to call another.

Avoid calling the same agent twice in one turn. Instead, prefer to call it once but provide everything
you need from that agent.
`;

// src/agents/adapters.ts
var fetchWithContextCall = async (context, ...params) => {
  const [input, init] = params;
  try {
    const headers = init?.headers ? Object.fromEntries(new Headers(init.headers).entries()) : {};
    const body = init?.body ? JSON.parse(init.body) : void 0;
    const agentName = headers[AGENT_NAME_HEADER];
    const stepName = agentName ? `Call Agent ${agentName}` : "Call Agent";
    const responseInfo = await context.call(stepName, {
      url: input.toString(),
      method: init?.method,
      headers,
      body
    });
    const responseHeaders = new Headers(
      Object.entries(responseInfo.header).reduce(
        (acc, [key, values]) => {
          acc[key] = values.join(", ");
          return acc;
        },
        {}
      )
    );
    return new Response(JSON.stringify(responseInfo.body), {
      status: responseInfo.status,
      headers: responseHeaders
    });
  } catch (error) {
    if (error instanceof Error && error.name === "WorkflowAbort") {
      throw error;
    } else {
      console.error("Error in fetch implementation:", error);
      throw error;
    }
  }
};
var createWorkflowModel = ({
  context,
  provider,
  providerParams
}) => {
  return provider({
    fetch: (...params) => fetchWithContextCall(context, ...params),
    ...providerParams
  });
};
var wrapTools = ({
  context,
  tools
}) => {
  return Object.fromEntries(
    Object.entries(tools).map((toolInfo) => {
      const [toolName, tool3] = toolInfo;
      const executeAsStep = "executeAsStep" in tool3 ? tool3.executeAsStep : true;
      const aiSDKTool = convertToAISDKTool(tool3);
      const execute = aiSDKTool.execute;
      if (execute && executeAsStep) {
        const wrappedExecute = (...params) => {
          return context.run(`Run tool ${toolName}`, () => execute(...params));
        };
        aiSDKTool.execute = wrappedExecute;
      }
      return [toolName, aiSDKTool];
    })
  );
};
var convertToAISDKTool = (tool3) => {
  const isLangchainTool = "invoke" in tool3;
  return isLangchainTool ? convertLangchainTool(tool3) : tool3;
};
var convertLangchainTool = (langchainTool) => {
  return (0, import_ai.tool)({
    description: langchainTool.description,
    parameters: langchainTool.schema,
    execute: async (...param) => langchainTool.invoke(...param)
  });
};

// src/agents/agent.ts
var import_zod = require("zod");
var import_ai2 = require("ai");

// src/serve/utils.ts
var isDisabledWorkflowContext = (context) => {
  return "disabled" in context;
};

// src/agents/agent.ts
var Agent = class {
  name;
  tools;
  maxSteps;
  background;
  model;
  temparature;
  context;
  constructor({ tools, maxSteps, background, name, model, temparature = 0.1 }, context) {
    this.name = name;
    this.tools = tools ?? {};
    this.maxSteps = maxSteps;
    this.background = background;
    this.model = model;
    this.temparature = temparature;
    this.context = context;
  }
  /**
   * Trigger the agent by passing a prompt
   *
   * @param prompt task to assign to the agent
   * @returns Response as `{ text: string }`
   */
  async call({ prompt }) {
    try {
      if (isDisabledWorkflowContext(this.context)) {
        await this.context.sleep("abort", 0);
      }
      const result = await (0, import_ai2.generateText)({
        model: this.model,
        tools: this.tools,
        maxSteps: this.maxSteps,
        system: this.background,
        prompt,
        headers: {
          [AGENT_NAME_HEADER]: this.name
        },
        temperature: this.temparature
      });
      return { text: result.text };
    } catch (error) {
      if (error instanceof import_ai2.ToolExecutionError) {
        if (error.cause instanceof Error && error.cause.name === "WorkflowAbort") {
          throw error.cause;
        } else if (error.cause instanceof import_ai2.ToolExecutionError && error.cause.cause instanceof Error && error.cause.cause.name === "WorkflowAbort") {
          throw error.cause.cause;
        } else {
          throw error;
        }
      } else {
        throw error;
      }
    }
  }
  /**
   * Convert the agent to a tool which can be used by other agents.
   *
   * @returns the agent as a tool
   */
  asTool() {
    const toolDescriptions = Object.values(this.tools).map((tool3) => tool3.description).join("\n");
    return (0, import_ai2.tool)({
      parameters: import_zod.z.object({ prompt: import_zod.z.string() }),
      execute: async ({ prompt }) => {
        return await this.call({ prompt });
      },
      description: `An AI Agent with the following background: ${this.background}Has access to the following tools: ${toolDescriptions}`
    });
  }
};
var ManagerAgent = class extends Agent {
  agents;
  /**
   * A manager agent which coordinates agents available to it to achieve a
   * given task
   *
   * @param name Name of the agent
   * @param background Background of the agent. If not passed, default will be used.
   * @param model LLM model to use
   * @param agents: List of agents available to the agent
   * @param maxSteps number of times the manager agent can call the LLM at most.
   *   If the agent abruptly stops execution after calling other agents, you may
   *   need to increase maxSteps
   */
  constructor({
    agents,
    background = MANAGER_AGENT_PROMPT,
    model,
    maxSteps,
    name = "manager llm"
  }, context) {
    super(
      {
        background,
        maxSteps,
        tools: Object.fromEntries(agents.map((agent) => [agent.name, agent.asTool()])),
        name,
        model
      },
      context
    );
    this.agents = agents;
  }
};

// src/agents/task.ts
var Task = class {
  context;
  taskParameters;
  constructor({
    context,
    taskParameters
  }) {
    this.context = context;
    this.taskParameters = taskParameters;
  }
  /**
   * Run the agents to complete the task
   *
   * @returns Result of the task as { text: string }
   */
  async run() {
    const { prompt, ...otherParams } = this.taskParameters;
    if ("agent" in otherParams) {
      const agent = otherParams.agent;
      const result = await agent.call({
        prompt
      });
      return { text: result.text };
    } else {
      const { agents, maxSteps, model, background } = otherParams;
      const managerAgent = new ManagerAgent(
        {
          model,
          maxSteps,
          agents,
          name: "Manager LLM",
          background
        },
        this.context
      );
      const result = await managerAgent.call({ prompt });
      return { text: result.text };
    }
  }
};

// src/agents/index.ts
var WorkflowAgents = class {
  context;
  constructor({ context }) {
    this.context = context;
  }
  /**
   * Defines an agent
   *
   * ```ts
   * const researcherAgent = context.agents.agent({
   *   model,
   *   name: 'academic',
   *   maxSteps: 2,
   *   tools: {
   *     wikiTool: new WikipediaQueryRun({
   *       topKResults: 1,
   *       maxDocContentLength: 500,
   *     })
   *   },
   *   background:
   *     'You are researcher agent with access to Wikipedia. ' +
   *     'Utilize Wikipedia as much as possible for correct information',
   * });
   * ```
   *
   * @param params agent parameters
   * @returns
   */
  agent(params) {
    const wrappedTools = wrapTools({ context: this.context, tools: params.tools });
    return new Agent(
      {
        ...params,
        tools: wrappedTools
      },
      this.context
    );
  }
  task(taskParameters) {
    return new Task({ context: this.context, taskParameters });
  }
  /**
   * creates an openai model for agents
   */
  openai(...params) {
    const [model, settings] = params;
    const { baseURL, apiKey, ...otherSettings } = settings ?? {};
    const openaiModel = this.AISDKModel({
      context: this.context,
      provider: import_openai3.createOpenAI,
      providerParams: { baseURL, apiKey, compatibility: "strict" }
    });
    return openaiModel(model, otherSettings);
  }
  AISDKModel = createWorkflowModel;
};

// src/context/context.ts
var WorkflowContext = class {
  executor;
  steps;
  /**
   * QStash client of the workflow
   *
   * Can be overwritten by passing `qstashClient` parameter in `serve`:
   *
   * ```ts
   * import { Client } from "@upstash/qstash"
   *
   * export const POST = serve(
   *   async (context) => {
   *     ...
   *   },
   *   {
   *     qstashClient: new Client({...})
   *   }
   * )
   * ```
   */
  qstashClient;
  /**
   * Run id of the workflow
   */
  workflowRunId;
  /**
   * URL of the workflow
   *
   * Can be overwritten by passing a `url` parameter in `serve`:
   *
   * ```ts
   * export const POST = serve(
   *   async (context) => {
   *     ...
   *   },
   *   {
   *     url: "new-url-value"
   *   }
   * )
   * ```
   */
  url;
  /**
   * URL to call in case of workflow failure with QStash failure callback
   *
   * https://upstash.com/docs/qstash/features/callbacks#what-is-a-failure-callback
   *
   * Can be overwritten by passing a `failureUrl` parameter in `serve`:
   *
   * ```ts
   * export const POST = serve(
   *   async (context) => {
   *     ...
   *   },
   *   {
   *     failureUrl: "new-url-value"
   *   }
   * )
   * ```
   */
  failureUrl;
  /**
   * Payload of the request which started the workflow.
   *
   * To specify its type, you can define `serve` as follows:
   *
   * ```ts
   * // set requestPayload type to MyPayload:
   * export const POST = serve<MyPayload>(
   *   async (context) => {
   *     ...
   *   }
   * )
   * ```
   *
   * By default, `serve` tries to apply `JSON.parse` to the request payload.
   * If your payload is encoded in a format other than JSON, you can utilize
   * the `initialPayloadParser` parameter:
   *
   * ```ts
   * export const POST = serve<MyPayload>(
   *   async (context) => {
   *     ...
   *   },
   *   {
   *     initialPayloadParser: (initialPayload) => {return doSomething(initialPayload)}
   *   }
   * )
   * ```
   */
  requestPayload;
  /**
   * headers of the initial request
   */
  headers;
  /**
   * Map of environment variables and their values.
   *
   * Can be set using the `env` option of serve:
   *
   * ```ts
   * export const POST = serve<MyPayload>(
   *   async (context) => {
   *     const key = context.env["API_KEY"];
   *   },
   *   {
   *     env: {
   *       "API_KEY": "*****";
   *     }
   *   }
   * )
   * ```
   *
   * Default value is set to `process.env`.
   */
  env;
  /**
   * Number of retries
   */
  retries;
  /**
   * Settings for controlling the number of active requests
   * and number of requests per second with the same key.
   */
  flowControl;
  constructor({
    qstashClient,
    workflowRunId,
    headers,
    steps,
    url,
    failureUrl,
    debug,
    initialPayload,
    env,
    retries,
    telemetry,
    invokeCount,
    flowControl
  }) {
    this.qstashClient = qstashClient;
    this.workflowRunId = workflowRunId;
    this.steps = steps;
    this.url = url;
    this.failureUrl = failureUrl;
    this.headers = headers;
    this.requestPayload = initialPayload;
    this.env = env ?? {};
    this.retries = retries ?? DEFAULT_RETRIES;
    this.flowControl = flowControl;
    this.executor = new AutoExecutor(this, this.steps, telemetry, invokeCount, debug);
  }
  /**
   * Executes a workflow step
   *
   * ```typescript
   * const result = await context.run("step 1", () => {
   *   return "result"
   * })
   * ```
   *
   * Can also be called in parallel and the steps will be executed
   * simulatenously:
   *
   * ```typescript
   * const [result1, result2] = await Promise.all([
   *   context.run("step 1", () => {
   *     return "result1"
   *   }),
   *   context.run("step 2", async () => {
   *     return await fetchResults()
   *   })
   * ])
   * ```
   *
   * @param stepName name of the step
   * @param stepFunction step function to be executed
   * @returns result of the step function
   */
  async run(stepName, stepFunction) {
    const wrappedStepFunction = () => this.executor.wrapStep(stepName, stepFunction);
    return await this.addStep(new LazyFunctionStep(stepName, wrappedStepFunction));
  }
  /**
   * Stops the execution for the duration provided.
   *
   * ```typescript
   * await context.sleep('sleep1', 3) // wait for three seconds
   * ```
   *
   * @param stepName
   * @param duration sleep duration in seconds
   * @returns undefined
   */
  async sleep(stepName, duration) {
    await this.addStep(new LazySleepStep(stepName, duration));
  }
  /**
   * Stops the execution until the date time provided.
   *
   * ```typescript
   * await context.sleepUntil('sleep1', Date.now() / 1000 + 3) // wait for three seconds
   * ```
   *
   * @param stepName
   * @param datetime time to sleep until. Can be provided as a number (in unix seconds),
   *   as a Date object or a string (passed to `new Date(datetimeString)`)
   * @returns undefined
   */
  async sleepUntil(stepName, datetime) {
    let time;
    if (typeof datetime === "number") {
      time = datetime;
    } else {
      datetime = typeof datetime === "string" ? new Date(datetime) : datetime;
      time = Math.round(datetime.getTime() / 1e3);
    }
    await this.addStep(new LazySleepUntilStep(stepName, time));
  }
  /**
   * Makes a third party call through QStash in order to make a
   * network call without consuming any runtime.
   *
   * ```ts
   * const { status, body } = await context.call<string>(
   *   "post call step",
   *   {
   *     url: "https://www.some-endpoint.com/api",
   *     method: "POST",
   *     body: "my-payload"
   *   }
   * );
   * ```
   *
   * tries to parse the result of the request as JSON. If it's
   * not a JSON which can be parsed, simply returns the response
   * body as it is.
   *
   * @param stepName
   * @param url url to call
   * @param method call method. "GET" by default.
   * @param body call body
   * @param headers call headers
   * @param retries number of call retries. 0 by default
   * @param timeout max duration to wait for the endpoint to respond. in seconds.
   * @returns call result as {
   *     status: number;
   *     body: unknown;
   *     header: Record<string, string[]>
   *   }
   */
  async call(stepName, settings) {
    const {
      url,
      method = "GET",
      body: requestBody,
      headers = {},
      retries = 0,
      timeout,
      flowControl
    } = settings;
    return await this.addStep(
      new LazyCallStep(
        stepName,
        url,
        method,
        requestBody,
        headers,
        retries,
        timeout,
        flowControl
      )
    );
  }
  /**
   * Pauses workflow execution until a specific event occurs or a timeout is reached.
   *
   *```ts
   * const result = await workflow.waitForEvent("payment-confirmed", {
   *   timeout: "5m"
   * });
   *```
   *
   * To notify a waiting workflow:
   *
   * ```ts
   * import { Client } from "@upstash/workflow";
   *
   * const client = new Client({ token: "<QSTASH_TOKEN>" });
   *
   * await client.notify({
   *   eventId: "payment.confirmed",
   *   data: {
   *     amount: 99.99,
   *     currency: "USD"
   *   }
   * })
   * ```
   *
   * Alternatively, you can use the `context.notify` method.
   *
   * @param stepName
   * @param eventId - Unique identifier for the event to wait for
   * @param options - Configuration options.
   * @returns `{ timeout: boolean, eventData: unknown }`.
   *   The `timeout` property specifies if the workflow has timed out. The `eventData`
   *   is the data passed when notifying this workflow of an event.
   */
  async waitForEvent(stepName, eventId, options = {}) {
    const { timeout = "7d" } = options;
    const timeoutStr = typeof timeout === "string" ? timeout : `${timeout}s`;
    return await this.addStep(new LazyWaitForEventStep(stepName, eventId, timeoutStr));
  }
  /**
   * Notify workflow runs waiting for an event
   *
   * ```ts
   * const { eventId, eventData, notifyResponse } = await context.notify(
   *   "notify step", "event-id", "event-data"
   * );
   * ```
   *
   * Upon `context.notify`, the workflow runs waiting for the given eventId (context.waitForEvent)
   * will receive the given event data and resume execution.
   *
   * The response includes the same eventId and eventData. Additionally, there is
   * a notifyResponse field which contains a list of `Waiter` objects, each corresponding
   * to a notified workflow run.
   *
   * @param stepName
   * @param eventId event id to notify
   * @param eventData event data to notify with
   * @returns notify response which has event id, event data and list of waiters which were notified
   */
  async notify(stepName, eventId, eventData) {
    return await this.addStep(
      new LazyNotifyStep(stepName, eventId, eventData, this.qstashClient.http)
    );
  }
  async invoke(stepName, settings) {
    return await this.addStep(new LazyInvokeStep(stepName, settings));
  }
  /**
   * Cancel the current workflow run
   *
   * Will throw WorkflowAbort to stop workflow execution.
   * Shouldn't be inside try/catch.
   */
  async cancel() {
    throw new WorkflowAbort("cancel", void 0, true);
  }
  /**
   * Adds steps to the executor. Needed so that it can be overwritten in
   * DisabledWorkflowContext.
   */
  async addStep(step) {
    return await this.executor.addStep(step);
  }
  get api() {
    return new WorkflowApi({
      context: this
    });
  }
  get agents() {
    return new WorkflowAgents({
      context: this
    });
  }
};

// src/logger.ts
var LOG_LEVELS = ["DEBUG", "INFO", "SUBMIT", "WARN", "ERROR"];
var WorkflowLogger = class _WorkflowLogger {
  logs = [];
  options;
  workflowRunId = void 0;
  constructor(options) {
    this.options = options;
  }
  async log(level, eventType, details) {
    if (this.shouldLog(level)) {
      const timestamp = Date.now();
      const logEntry = {
        timestamp,
        workflowRunId: this.workflowRunId ?? "",
        logLevel: level,
        eventType,
        details
      };
      this.logs.push(logEntry);
      if (this.options.logOutput === "console") {
        this.writeToConsole(logEntry);
      }
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
  }
  setWorkflowRunId(workflowRunId) {
    this.workflowRunId = workflowRunId;
  }
  writeToConsole(logEntry) {
    const JSON_SPACING = 2;
    const logMethod = logEntry.logLevel === "ERROR" ? console.error : logEntry.logLevel === "WARN" ? console.warn : console.log;
    logMethod(JSON.stringify(logEntry, void 0, JSON_SPACING));
  }
  shouldLog(level) {
    return LOG_LEVELS.indexOf(level) >= LOG_LEVELS.indexOf(this.options.logLevel);
  }
  static getLogger(verbose) {
    if (typeof verbose === "object") {
      return verbose;
    } else {
      return verbose ? new _WorkflowLogger({
        logLevel: "INFO",
        logOutput: "console"
      }) : void 0;
    }
  }
};

// src/serve/authorization.ts
var import_qstash8 = require("@upstash/qstash");
var DisabledWorkflowContext = class _DisabledWorkflowContext extends WorkflowContext {
  static disabledMessage = "disabled-qstash-worklfow-run";
  disabled = true;
  /**
   * overwrite the WorkflowContext.addStep method to always raise WorkflowAbort
   * error in order to stop the execution whenever we encounter a step.
   *
   * @param _step
   */
  async addStep(_step) {
    throw new WorkflowAbort(_DisabledWorkflowContext.disabledMessage);
  }
  /**
   * overwrite cancel method to do nothing
   */
  async cancel() {
    return;
  }
  /**
   * copies the passed context to create a DisabledWorkflowContext. Then, runs the
   * route function with the new context.
   *
   * - returns "run-ended" if there are no steps found or
   *      if the auth failed and user called `return`
   * - returns "step-found" if DisabledWorkflowContext.addStep is called.
   * - if there is another error, returns the error.
   *
   * @param routeFunction
   */
  static async tryAuthentication(routeFunction, context) {
    const disabledContext = new _DisabledWorkflowContext({
      qstashClient: new import_qstash8.Client({
        baseUrl: "disabled-client",
        token: "disabled-client"
      }),
      workflowRunId: context.workflowRunId,
      headers: context.headers,
      steps: [],
      url: context.url,
      failureUrl: context.failureUrl,
      initialPayload: context.requestPayload,
      env: context.env,
      retries: context.retries,
      flowControl: context.flowControl
    });
    try {
      await routeFunction(disabledContext);
    } catch (error) {
      if (error instanceof WorkflowAbort && error.stepName === this.disabledMessage) {
        return ok("step-found");
      }
      return err(error);
    }
    return ok("run-ended");
  }
};

// src/workflow-parser.ts
var getPayload = async (request) => {
  try {
    return await request.text();
  } catch {
    return;
  }
};
var processRawSteps = (rawSteps) => {
  const [encodedInitialPayload, ...encodedSteps] = rawSteps;
  const rawInitialPayload = decodeBase64(encodedInitialPayload.body);
  const initialStep = {
    stepId: 0,
    stepName: "init",
    stepType: "Initial",
    out: rawInitialPayload,
    concurrent: NO_CONCURRENCY
  };
  const stepsToDecode = encodedSteps.filter((step) => step.callType === "step");
  const otherSteps = stepsToDecode.map((rawStep) => {
    const step = JSON.parse(decodeBase64(rawStep.body));
    if (step.waitEventId) {
      const newOut = {
        eventData: step.out ? decodeBase64(step.out) : void 0,
        timeout: step.waitTimeout ?? false
      };
      step.out = newOut;
    }
    return step;
  });
  const steps = [initialStep, ...otherSteps];
  return {
    rawInitialPayload,
    steps
  };
};
var deduplicateSteps = (steps) => {
  const targetStepIds = [];
  const stepIds = [];
  const deduplicatedSteps = [];
  for (const step of steps) {
    if (step.stepId === 0) {
      if (!targetStepIds.includes(step.targetStep ?? 0)) {
        deduplicatedSteps.push(step);
        targetStepIds.push(step.targetStep ?? 0);
      }
    } else {
      if (!stepIds.includes(step.stepId)) {
        deduplicatedSteps.push(step);
        stepIds.push(step.stepId);
      }
    }
  }
  return deduplicatedSteps;
};
var checkIfLastOneIsDuplicate = async (steps, debug) => {
  if (steps.length < 2) {
    return false;
  }
  const lastStep = steps.at(-1);
  const lastStepId = lastStep.stepId;
  const lastTargetStepId = lastStep.targetStep;
  for (let index = 0; index < steps.length - 1; index++) {
    const step = steps[index];
    if (step.stepId === lastStepId && step.targetStep === lastTargetStepId) {
      const message = `Upstash Workflow: The step '${step.stepName}' with id '${step.stepId}'  has run twice during workflow execution. Rest of the workflow will continue running as usual.`;
      await debug?.log("WARN", "RESPONSE_DEFAULT", message);
      console.warn(message);
      return true;
    }
  }
  return false;
};
var validateRequest = (request) => {
  const versionHeader = request.headers.get(WORKFLOW_PROTOCOL_VERSION_HEADER);
  const isFirstInvocation = !versionHeader;
  if (!isFirstInvocation && versionHeader !== WORKFLOW_PROTOCOL_VERSION) {
    throw new WorkflowError(
      `Incompatible workflow sdk protocol version. Expected ${WORKFLOW_PROTOCOL_VERSION}, got ${versionHeader} from the request.`
    );
  }
  const workflowRunId = isFirstInvocation ? getWorkflowRunId() : request.headers.get(WORKFLOW_ID_HEADER) ?? "";
  if (workflowRunId.length === 0) {
    throw new WorkflowError("Couldn't get workflow id from header");
  }
  return {
    isFirstInvocation,
    workflowRunId
  };
};
var parseRequest = async (requestPayload, isFirstInvocation, workflowRunId, requester, messageId, debug) => {
  if (isFirstInvocation) {
    return {
      rawInitialPayload: requestPayload ?? "",
      steps: [],
      isLastDuplicate: false,
      workflowRunEnded: false
    };
  } else {
    let rawSteps;
    if (!requestPayload) {
      await debug?.log(
        "INFO",
        "ENDPOINT_START",
        "request payload is empty, steps will be fetched from QStash."
      );
      const { steps: fetchedSteps, workflowRunEnded } = await getSteps(
        requester,
        workflowRunId,
        messageId,
        debug
      );
      if (workflowRunEnded) {
        return {
          rawInitialPayload: void 0,
          steps: void 0,
          isLastDuplicate: void 0,
          workflowRunEnded: true
        };
      }
      rawSteps = fetchedSteps;
    } else {
      rawSteps = JSON.parse(requestPayload);
    }
    const { rawInitialPayload, steps } = processRawSteps(rawSteps);
    const isLastDuplicate = await checkIfLastOneIsDuplicate(steps, debug);
    const deduplicatedSteps = deduplicateSteps(steps);
    return {
      rawInitialPayload,
      steps: deduplicatedSteps,
      isLastDuplicate,
      workflowRunEnded: false
    };
  }
};
var handleFailure = async (request, requestPayload, qstashClient, initialPayloadParser, routeFunction, failureFunction, env, retries, flowControl, debug) => {
  if (request.headers.get(WORKFLOW_FAILURE_HEADER) !== "true") {
    return ok("not-failure-callback");
  }
  if (!failureFunction) {
    return err(
      new WorkflowError(
        "Workflow endpoint is called to handle a failure, but a failureFunction is not provided in serve options. Either provide a failureUrl or a failureFunction."
      )
    );
  }
  try {
    const { status, header, body, url, sourceBody, workflowRunId } = JSON.parse(requestPayload);
    const decodedBody = body ? decodeBase64(body) : "{}";
    const errorPayload = JSON.parse(decodedBody);
    const workflowContext = new WorkflowContext({
      qstashClient,
      workflowRunId,
      initialPayload: sourceBody ? initialPayloadParser(decodeBase64(sourceBody)) : void 0,
      headers: recreateUserHeaders(request.headers),
      steps: [],
      url,
      failureUrl: url,
      debug,
      env,
      retries,
      flowControl,
      telemetry: void 0
      // not going to make requests in authentication check
    });
    const authCheck = await DisabledWorkflowContext.tryAuthentication(
      routeFunction,
      workflowContext
    );
    if (authCheck.isErr()) {
      await debug?.log("ERROR", "ERROR", { error: authCheck.error.message });
      throw authCheck.error;
    } else if (authCheck.value === "run-ended") {
      return err(new WorkflowError("Not authorized to run the failure function."));
    }
    await failureFunction({
      context: workflowContext,
      failStatus: status,
      failResponse: errorPayload.message,
      failHeaders: header
    });
  } catch (error) {
    return err(error);
  }
  return ok("is-failure-callback");
};

// src/serve/options.ts
var import_qstash9 = require("@upstash/qstash");
var import_qstash10 = require("@upstash/qstash");
var processOptions = (options) => {
  const environment = options?.env ?? (typeof process === "undefined" ? {} : process.env);
  const receiverEnvironmentVariablesSet = Boolean(
    environment.QSTASH_CURRENT_SIGNING_KEY && environment.QSTASH_NEXT_SIGNING_KEY
  );
  return {
    qstashClient: new import_qstash10.Client({
      baseUrl: environment.QSTASH_URL,
      token: environment.QSTASH_TOKEN
    }),
    onStepFinish: (workflowRunId, finishCondition) => {
      if (finishCondition === "auth-fail") {
        console.error(AUTH_FAIL_MESSAGE);
        return new Response(
          JSON.stringify({
            message: AUTH_FAIL_MESSAGE,
            workflowRunId
          }),
          {
            status: 400
          }
        );
      }
      return new Response(JSON.stringify({ workflowRunId }), {
        status: 200
      });
    },
    initialPayloadParser: (initialRequest) => {
      if (!initialRequest) {
        return void 0;
      }
      try {
        const parsed = JSON.parse(initialRequest);
        return options?.schema ? options.schema.parse(parsed) : parsed;
      } catch (error) {
        if (error instanceof SyntaxError) {
          return initialRequest;
        }
        throw error;
      }
    },
    receiver: receiverEnvironmentVariablesSet ? new import_qstash9.Receiver({
      currentSigningKey: environment.QSTASH_CURRENT_SIGNING_KEY,
      nextSigningKey: environment.QSTASH_NEXT_SIGNING_KEY
    }) : void 0,
    baseUrl: environment.UPSTASH_WORKFLOW_URL,
    env: environment,
    retries: DEFAULT_RETRIES,
    useJSONContent: false,
    disableTelemetry: false,
    onError: console.error,
    ...options
  };
};
var determineUrls = async (request, url, baseUrl, failureFunction, failureUrl, debug) => {
  const initialWorkflowUrl = url ?? request.url;
  const workflowUrl = baseUrl ? initialWorkflowUrl.replace(/^(https?:\/\/[^/]+)(\/.*)?$/, (_, matchedBaseUrl, path) => {
    return baseUrl + (path || "");
  }) : initialWorkflowUrl;
  if (workflowUrl !== initialWorkflowUrl) {
    await debug?.log("WARN", "ENDPOINT_START", {
      warning: `Upstash Workflow: replacing the base of the url with "${baseUrl}" and using it as workflow endpoint.`,
      originalURL: initialWorkflowUrl,
      updatedURL: workflowUrl
    });
  }
  const workflowFailureUrl = failureFunction ? workflowUrl : failureUrl;
  if (workflowUrl.includes("localhost")) {
    await debug?.log("WARN", "ENDPOINT_START", {
      message: `Workflow URL contains localhost. This can happen in local development, but shouldn't happen in production unless you have a route which contains localhost. Received: ${workflowUrl}`
    });
  }
  if (!(workflowUrl.startsWith("http://") || workflowUrl.startsWith("https://"))) {
    throw new WorkflowError(
      `Workflow URL should start with 'http://' or 'https://'. Recevied is '${workflowUrl}'`
    );
  }
  return {
    workflowUrl,
    workflowFailureUrl
  };
};
var AUTH_FAIL_MESSAGE = `Failed to authenticate Workflow request. If this is unexpected, see the caveat https://upstash.com/docs/workflow/basics/caveats#avoid-non-deterministic-code-outside-context-run`;

// src/serve/index.ts
var serveBase = (routeFunction, telemetry, options) => {
  const {
    qstashClient,
    onStepFinish,
    initialPayloadParser,
    url,
    verbose,
    receiver,
    failureUrl,
    failureFunction,
    baseUrl,
    env,
    retries,
    useJSONContent,
    disableTelemetry,
    flowControl,
    onError
  } = processOptions(options);
  telemetry = disableTelemetry ? void 0 : telemetry;
  const debug = WorkflowLogger.getLogger(verbose);
  const handler = async (request) => {
    await debug?.log("INFO", "ENDPOINT_START");
    const { workflowUrl, workflowFailureUrl } = await determineUrls(
      request,
      url,
      baseUrl,
      failureFunction,
      failureUrl,
      debug
    );
    const requestPayload = await getPayload(request) ?? "";
    await verifyRequest(requestPayload, request.headers.get("upstash-signature"), receiver);
    const { isFirstInvocation, workflowRunId } = validateRequest(request);
    debug?.setWorkflowRunId(workflowRunId);
    const { rawInitialPayload, steps, isLastDuplicate, workflowRunEnded } = await parseRequest(
      requestPayload,
      isFirstInvocation,
      workflowRunId,
      qstashClient.http,
      request.headers.get("upstash-message-id"),
      debug
    );
    if (workflowRunEnded) {
      return onStepFinish(workflowRunId, "workflow-already-ended");
    }
    if (isLastDuplicate) {
      return onStepFinish(workflowRunId, "duplicate-step");
    }
    const failureCheck = await handleFailure(
      request,
      requestPayload,
      qstashClient,
      initialPayloadParser,
      routeFunction,
      failureFunction,
      env,
      retries,
      flowControl,
      debug
    );
    if (failureCheck.isErr()) {
      throw failureCheck.error;
    } else if (failureCheck.value === "is-failure-callback") {
      await debug?.log("WARN", "RESPONSE_DEFAULT", "failureFunction executed");
      return onStepFinish(workflowRunId, "failure-callback");
    }
    const invokeCount = Number(request.headers.get(WORKFLOW_INVOKE_COUNT_HEADER) ?? "0");
    const workflowContext = new WorkflowContext({
      qstashClient,
      workflowRunId,
      initialPayload: initialPayloadParser(rawInitialPayload),
      headers: recreateUserHeaders(request.headers),
      steps,
      url: workflowUrl,
      failureUrl: workflowFailureUrl,
      debug,
      env,
      retries,
      telemetry,
      invokeCount,
      flowControl
    });
    const authCheck = await DisabledWorkflowContext.tryAuthentication(
      routeFunction,
      workflowContext
    );
    if (authCheck.isErr()) {
      await debug?.log("ERROR", "ERROR", { error: authCheck.error.message });
      throw authCheck.error;
    } else if (authCheck.value === "run-ended") {
      await debug?.log("ERROR", "ERROR", { error: AUTH_FAIL_MESSAGE });
      return onStepFinish(
        isFirstInvocation ? "no-workflow-id" : workflowContext.workflowRunId,
        "auth-fail"
      );
    }
    const callReturnCheck = await handleThirdPartyCallResult({
      request,
      requestPayload: rawInitialPayload,
      client: qstashClient,
      workflowUrl,
      failureUrl: workflowFailureUrl,
      retries,
      flowControl,
      telemetry,
      debug
    });
    if (callReturnCheck.isErr()) {
      await debug?.log("ERROR", "SUBMIT_THIRD_PARTY_RESULT", {
        error: callReturnCheck.error.message
      });
      throw callReturnCheck.error;
    } else if (callReturnCheck.value === "continue-workflow") {
      const result = isFirstInvocation ? await triggerFirstInvocation({
        workflowContext,
        useJSONContent,
        telemetry,
        debug,
        invokeCount
      }) : await triggerRouteFunction({
        onStep: async () => routeFunction(workflowContext),
        onCleanup: async (result2) => {
          await triggerWorkflowDelete(workflowContext, result2, debug);
        },
        onCancel: async () => {
          await makeCancelRequest(workflowContext.qstashClient.http, workflowRunId);
        },
        debug
      });
      if (result.isErr()) {
        await debug?.log("ERROR", "ERROR", { error: result.error.message });
        throw result.error;
      }
      await debug?.log("INFO", "RESPONSE_WORKFLOW");
      return onStepFinish(workflowContext.workflowRunId, "success");
    } else if (callReturnCheck.value === "workflow-ended") {
      return onStepFinish(workflowContext.workflowRunId, "workflow-already-ended");
    }
    await debug?.log("INFO", "RESPONSE_DEFAULT");
    return onStepFinish("no-workflow-id", "fromCallback");
  };
  const safeHandler = async (request) => {
    try {
      return await handler(request);
    } catch (error) {
      const formattedError = formatWorkflowError(error);
      try {
        onError?.(error);
      } catch (onErrorError) {
        const formattedOnErrorError = formatWorkflowError(onErrorError);
        const errorMessage = `Error while running onError callback: '${formattedOnErrorError.message}'.
Original error: '${formattedError.message}'`;
        console.error(errorMessage);
        return new Response(errorMessage, {
          status: 500
        });
      }
      return new Response(JSON.stringify(formattedError), {
        status: 500
      });
    }
  };
  return { handler: safeHandler };
};

// platforms/solidjs.ts
var serve = (routeFunction, options) => {
  const telemetry = {
    sdk: SDK_TELEMETRY,
    framework: "solidjs",
    runtime: process.versions.bun ? `bun@${process.versions.bun}/node@${process.version}` : `node@${process.version}`
  };
  const handler = async (event) => {
    const method = event.request.method;
    if (method.toUpperCase() !== "POST") {
      return new Response("Only POST requests are allowed in worklfows", {
        status: 405
      });
    }
    const { handler: serveHandler } = serveBase(routeFunction, telemetry, options);
    return await serveHandler(event.request);
  };
  return { POST: handler };
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  serve
});
